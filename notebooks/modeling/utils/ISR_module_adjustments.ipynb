{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ISR_module_adjustments.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Notebook author: Elena Gronskaya"
      ],
      "metadata": {
        "id": "Y7p7ULN2sNBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this notebook is to adjust the functions of the original ISR repo to make them compatible for working with raw TIF files sourced from Google Earth Engine. If using PNG satellite images (pre-processed with GDAL_transformer_PNG.ipynb), use ISR_module_adjustments_PNG.ipynb.\n",
        "\n",
        "Usage: the cells in this notebook should be copied to the training/prediction notebooks and ran at the beginning (if ISR is imported through pip install). Alternatively, these changes can be applied to a local ISR repo."
      ],
      "metadata": {
        "id": "-zaEigTHsM04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gast\"==0.3.2\"\n",
        "!pip install ISR\n",
        "!pip install 'h5py==2.10.0' --force-reinstall"
      ],
      "metadata": {
        "id": "DIgg1G95jzU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ISR\n",
        "import numpy as np\n",
        "import ISR.utils.datahandler\n",
        "import ISR.predict.predictor"
      ],
      "metadata": {
        "id": "T_HUNgaQj0uF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _make_img_list(self):\n",
        "  \"\"\" Creates a dictionary of lists of the acceptable images contained in lr_dir and hr_dir. \"\"\"\n",
        "        \n",
        "  for res in ['hr', 'lr']:\n",
        "    file_names = os.listdir(self.folders[res])\n",
        "    file_names = [file for file in file_names]\n",
        "    self.img_list[res] = np.sort(file_names)\n",
        "        \n",
        "  if self.n_validation_samples:\n",
        "    samples = np.random.choice(\n",
        "        range(len(self.img_list['hr'])), self.n_validation_samples, replace=False\n",
        "        )\n",
        "    for res in ['hr', 'lr']:\n",
        "      self.img_list[res] = self.img_list[res][samples]\n",
        "\n",
        "ISR.utils.datahandler.DataHandler._make_img_list = _make_img_list  "
      ],
      "metadata": {
        "id": "tV9HJA7djaKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyArQApejqYe"
      },
      "outputs": [],
      "source": [
        "def get_batch(self, batch_size, idx=None, flatness=0.0):\n",
        "  \"\"\"\n",
        "  Returns a dictionary with keys ('lr', 'hr') containing training batches\n",
        "  of Low Res and High Res image patches.\n",
        "  Args:\n",
        "      batch_size: integer.\n",
        "      flatness: float in [0,1], is the patch \"flatness\" threshold.\n",
        "    Determines what level of detail the patches need to meet. 0 means any patch is accepted.\n",
        "  \"\"\"\n",
        "        \n",
        "  if not idx:\n",
        "      # randomly select one image. idx is given at validation time.\n",
        "    idx = np.random.choice(range(len(self.img_list['hr'])))\n",
        "  img = {}\n",
        "  for res in ['lr', 'hr']:\n",
        "    img_path = os.path.join(self.folders[res], self.img_list[res][idx])\n",
        "\n",
        "    # different normalization for landsat and sentinel images\n",
        "    if res == 'lr':\n",
        "      img[res] = ((imageio.imread(img_path).astype(int)*0.0000275-0.2)*255*4).astype(int) #landsat\n",
        "    else:\n",
        "      img[res] = ((imageio.imread(img_path).astype(int)*255/3558)*1.4).astype(int) #sentinel\n",
        "\n",
        "    img[res][img[res]>255] = 255\n",
        "    img[res][img[res]<0] = 0\n",
        "    img[res] = img[res] / 255.0\n",
        "\n",
        "  batch = self._crop_imgs(img, batch_size, flatness)\n",
        "  transforms = np.random.randint(0, 3, (batch_size, 2))\n",
        "  batch['lr'] = self._transform_batch(batch['lr'], transforms)\n",
        "  batch['hr'] = self._transform_batch(batch['hr'], transforms)\n",
        "          \n",
        "  return batch\n",
        "\n",
        "ISR.utils.datahandler.DataHandler.get_batch = get_batch  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "from pathlib import Path\n",
        "from ISR.utils.logger import get_logger\n",
        "import yaml\n",
        "\n",
        "def _forward_pass(self, file_path):\n",
        "  lr_img = ((imageio.imread(file_path).astype(int)*0.0000275-0.2)*255*4).astype(int)\n",
        "  lr_img[lr_img>255] = 255\n",
        "  lr_img[lr_img<0] = 0\n",
        "\n",
        "  if lr_img.shape[2] == 3:\n",
        "    sr_img = self.model.predict(lr_img)\n",
        "    return sr_img\n",
        "  else:\n",
        "    self.logger.error('{} is not an image with 3 channels.'.format(file_path))\n",
        "\n",
        "ISR.predict.predictor.Predictor._forward_pass = _forward_pass\n",
        "\n",
        "def predictor_init(self, input_dir, output_dir='./data/output', verbose=True):\n",
        "\n",
        "  self.input_dir = Path(input_dir)\n",
        "  self.data_name = self.input_dir.name\n",
        "  self.output_dir = Path(output_dir) / self.data_name\n",
        "  self.logger = get_logger(__name__)\n",
        "  if not verbose:\n",
        "    self.logger.setLevel(40)\n",
        "  self.extensions = ('.jpeg', '.jpg', '.png','.tif')  # file extensions that are admitted\n",
        "  self.img_ls = [f for f in self.input_dir.iterdir() if f.suffix in self.extensions]\n",
        "  if len(self.img_ls) < 1:\n",
        "    self.logger.error('No valid image files found (check config file).')\n",
        "    raise ValueError('No valid image files found (check config file).')\n",
        "  # Create results folder\n",
        "  if not self.output_dir.exists():\n",
        "    self.logger.info('Creating output directory:\\n{}'.format(self.output_dir))\n",
        "    self.output_dir.mkdir(parents=True)\n",
        "\n",
        "ISR.predict.predictor.Predictor.__init__ = predictor_init\n",
        "\n",
        "# fix for posix path error\n",
        "\n",
        "def _load_weights(self):\n",
        "    \"\"\" Invokes the model's load weights function if any weights are provided. \"\"\"\n",
        "    if self.weights_path is not None:\n",
        "        self.logger.info('Loaded weights from \\n > {}'.format(self.weights_path))\n",
        "        # loading by name automatically excludes the vgg layers\n",
        "        self.model.model.load_weights(str(self.weights_path))\n",
        "    else:\n",
        "        self.logger.error('Error: Weights path not specified (check config file).')\n",
        "        raise ValueError('Weights path not specified (check config file).')\n",
        "\n",
        "    session_config_path = self.weights_path.parent / 'session_config.yml'\n",
        "    if session_config_path.exists():\n",
        "        conf = yaml.load(session_config_path.read_text(), Loader=yaml.FullLoader)\n",
        "    else:\n",
        "        self.logger.warning('Could not find weights training configuration')\n",
        "        conf = {}\n",
        "    conf.update({'pre-trained-weights': self.weights_path.name})\n",
        "    return conf\n",
        "\n",
        "ISR.predict.predictor.Predictor._load_weights=_load_weights       "
      ],
      "metadata": {
        "id": "wNA8wpDslecd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fix for posix path error\n",
        "import ISR.train.trainer\n",
        "\n",
        "def _load_weights(self):\n",
        "    \"\"\"\n",
        "    Loads the pretrained weights from the given path, if any is provided.\n",
        "    If a discriminator is defined, does the same.\n",
        "    \"\"\"\n",
        "    \n",
        "    if self.weights_generator:\n",
        "        self.model.get_layer('generator').load_weights(str(self.weights_generator))\n",
        "    \n",
        "    if self.discriminator:\n",
        "        if self.weights_discriminator:\n",
        "            self.model.get_layer('discriminator').load_weights(str(self.weights_discriminator))\n",
        "            self.discriminator.model.load_weights(str(self.weights_discriminator))\n",
        "\n",
        "ISR.train.trainer.Trainer._load_weights=_load_weights  "
      ],
      "metadata": {
        "id": "q-1dw_EzkIYM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}