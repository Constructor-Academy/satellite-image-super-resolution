{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SRGAN_Training_L8_S2.ipynb","provenance":[{"file_id":"1EvsSeiZJa_V82BHvsq412fjP4CD9NOwC","timestamp":1650927141008},{"file_id":"128Op2WL5j17RNTCvQGozmVTuyU0zEaSc","timestamp":1650879106466}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Enhanced Deep Residual Networks (EDSR) & \n","# Super Resolution Generative Adversarial Networks (SRGAN)\n"],"metadata":{"id":"h0CFUWdFoRbk"}},{"cell_type":"markdown","source":["\n","Notebook author: Dipanjan (DJ) Sarkar  & Ozgun Haznedar "],"metadata":{"id":"c00dJTiYo37q"}},{"cell_type":"markdown","source":["## In this notebook, EDSR and SRGAN EDSR models are built and trained."],"metadata":{"id":"dL9MwzBapEQc"}},{"cell_type":"code","metadata":{"id":"SJjU0-O02mQX"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"22-x9YnJLaDs"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eTadh2Kc2drt"},"source":["import tensorflow as tf\n","from tqdm import tqdm\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","from glob import glob"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tdcfv2sG2u9A"},"source":["tf.__version__"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NXRJDeaWzD1A"},"source":["# Uncomment to download the DIV2K dataset\n","\"\"\"\n","lr_dataset = f'DIV2K_train_LR_bicubic_X4.zip'\n","lr_datset_url = f'http://data.vision.ee.ethz.ch/cvl/DIV2K/{lr_dataset}'\n","\n","hr_dataset = f'DIV2K_train_HR.zip'\n","hr_datset_url = f'http://data.vision.ee.ethz.ch/cvl/DIV2K/{hr_dataset}'\n","\n","download_dir = './div2k_data/images'\n","download_dir = os.path.abspath(download_dir)\n","\n","tf.keras.utils.get_file(lr_dataset, lr_datset_url, \n","                        cache_subdir=download_dir, \n","                        extract=True)\n","tf.keras.utils.get_file(hr_dataset, hr_datset_url, \n","                        cache_subdir=download_dir, \n","                        extract=True)\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1tIRQ61S5Lkg"},"source":["\"\"\"\n","download_dir = './div2k_data/images'\n","download_dir = os.path.abspath(download_dir)\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YnxNIEi06rCG"},"source":["AUTOTUNE = tf.data.experimental.AUTOTUNE\n","\n","lr_dir = f\"LR TRAIN DIRECTORY\"\n","hr_dir = f\"HR TRAIN DIRECTORY\"\n","\n","lr_images = sorted(glob(lr_dir+'/*.*'))\n","hr_images = sorted(glob(hr_dir+'/*.*'))\n","\n","lr_ds = tf.data.Dataset.from_tensor_slices(lr_images)\n","lr_ds = lr_ds.map(tf.io.read_file)\n","lr_ds = (lr_ds.map(lambda x: tf.image.decode_png(x, channels=3),\n","                  num_parallel_calls=AUTOTUNE)\n","              .cache())\n","\n","hr_ds = tf.data.Dataset.from_tensor_slices(hr_images)\n","hr_ds = hr_ds.map(tf.io.read_file)\n","hr_ds = (hr_ds.map(lambda x: tf.image.decode_png(x, channels=3),\n","                  num_parallel_calls=AUTOTUNE)\n","              .cache())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jk9ek4sCBbRG"},"source":["def random_crop(lr_img, hr_img):\n","  hr_crop_size=96; scale=3\n","  lr_crop_size = 32\n","  lr_img_shape = tf.shape(lr_img)[:2]\n","\n","  lr_w = tf.random.uniform(shape=(), \n","                           maxval=lr_img_shape[1] - lr_crop_size + 1, \n","                           dtype=tf.int32)\n","  lr_h = tf.random.uniform(shape=(), \n","                           maxval=lr_img_shape[0] - lr_crop_size + 1, \n","                           dtype=tf.int32)\n","\n","  hr_w = lr_w * scale\n","  hr_h = lr_h * scale\n","  lr_img_crop = lr_img[lr_h:lr_h + lr_crop_size, \n","                          lr_w:lr_w + lr_crop_size]\n","  hr_img_crop = hr_img[hr_h:hr_h + hr_crop_size, \n","                          hr_w:hr_w + hr_crop_size]\n","\n","  return lr_img_crop, hr_img_crop\n","\n","\n","def random_flip(lr_img, hr_img):\n","  rn = tf.random.uniform(shape=(), maxval=1)\n","  return tf.cond(rn < 0.5,\n","                  lambda: (lr_img, hr_img),\n","                  lambda: (tf.image.flip_left_right(lr_img),\n","                          tf.image.flip_left_right(hr_img)))\n","\n","\n","def random_rotate(lr_img, hr_img):\n","  rn = tf.random.uniform(shape=(), \n","                         maxval=4, dtype=tf.int32)\n","  return (tf.image.rot90(lr_img, rn), \n","          tf.image.rot90(hr_img, rn))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YSWts1k1BczP"},"source":["AUTOTUNE = tf.data.experimental.AUTOTUNE\n","BATCH_SIZE = 16\n","\n","train_ds = tf.data.Dataset.zip((lr_ds, hr_ds))\n","train_ds = train_ds.map(lambda lr, hr: random_crop(lr, hr), \n","                        num_parallel_calls=AUTOTUNE)\n","train_ds = train_ds.map(random_rotate, \n","                        num_parallel_calls=AUTOTUNE)\n","train_ds = train_ds.map(random_flip, \n","                        num_parallel_calls=AUTOTUNE)\n","train_ds = train_ds.batch(BATCH_SIZE)\n","train_ds = train_ds.repeat()\n","train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vI4ZoIyZ1oOH"},"source":["from tensorflow.keras.layers import Add, Conv2D, Input, Lambda\n","from tensorflow.keras.models import Model\n","import numpy as np\n","import tensorflow as tf\n","\n","DIV2K_RGB_MEAN = np.array([0.4488, 0.4371, 0.4040]) * 255\n","\n","def normalize(x):\n","  return (x - DIV2K_RGB_MEAN) / 127.5\n","\n","\n","def denormalize(x):\n","  return x * 127.5 + DIV2K_RGB_MEAN\n","\n","\n","def residual_block(inp):\n","  \"\"\"Creates an EDSR residual block.\"\"\"\n","  x = Conv2D(64, 3, padding='same', activation='relu')(inp)\n","  x = Conv2D(64, 3, padding='same')(x)\n","  x = Add()([inp, x])\n","  return x\n","\n","\n","def edsr_model_arch(num_residual_blocks):\n","  \"\"\"Creates an EDSR model.\"\"\"\n","  inp = Input(shape=(None, None, 3))\n","  x = Lambda(normalize)(inp)\n","\n","  x = rb = Conv2D(64, 3, padding='same')(x)\n","  for i in range(num_residual_blocks):\n","      rb = residual_block(rb)\n","  rb = Conv2D(64, 3, padding='same')(rb)\n","  x = Add()([x, rb])\n","\n","  x = Conv2D(64 * (3 ** 2), 3, padding='same')(x)\n","  x = Lambda(lambda x: tf.nn.depth_to_space(x, 3))(x)\n","  #x = Conv2D(64 * (3 ** 2), 3, padding='same')(x)\n","  #x = Lambda(lambda x: tf.nn.depth_to_space(x, 3))(x)\n","  x = Conv2D(3, 3, padding='same')(x)\n","\n","  out = Lambda(denormalize)(x)\n","\n","  return Model(inp, out, name=\"edsr_model\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1z7MbeYE1pki"},"source":["edsr_model = edsr_model_arch(num_residual_blocks=16)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AE7E8IgF4i1L"},"source":["edsr_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U-2_040k0gqO"},"source":["from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n","\n","optim = Adam(learning_rate=PiecewiseConstantDecay(boundaries=[200000, 400000], \n","                                                       values=[1e-4, 5e-5, 2.5e-5]))\n","edsr_model.compile(optimizer=optim, loss='mean_absolute_error')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M080L-Bt1U4s"},"source":["history = edsr_model.fit(train_ds, epochs=500, steps_per_epoch=1000)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"adlRuFrCZQ4T"},"source":["f, ax = plt.subplots(1, 2, figsize=(10, 4))\n","\n","epochs = history.epoch\n","learning_rates = [optim.lr(e*1000).numpy() for e in epochs]\n","losses = history.history['loss']\n","\n","plt.subplot(121)\n","plt.plot(epochs, learning_rates, 'k--')\n","plt.title('Learning Rate History')\n","plt.subplot(122)\n","plt.plot(epochs, losses, 'k')\n","plt.title('Loss History');"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"orOrtfXOCdMe"},"source":["from PIL import Image\n","\n","def run_sr_inference(img_path, model):\n","  lr_file = tf.io.read_file(img_path)\n","  lr_img = tf.image.decode_png(lr_file, channels=3)\n","  lr_img_npy = lr_img.numpy()\n","\n","  upsamp_img = (np.asarray(\n","                Image.fromarray(lr_img_npy)\n","                     .resize(size=(lr_img_npy.shape[1]*3, \n","                                   lr_img_npy.shape[0]*3), \n","                             resample=Image.BICUBIC)))\n","  \n","  lr_img = tf.expand_dims(lr_img, axis=0)\n","  lr_img = tf.cast(lr_img, tf.float32)\n","  sr_img = model(lr_img)\n","  sr_img = tf.clip_by_value(sr_img, 0, 255)\n","  sr_img = tf.cast(sr_img, tf.uint8)\n","\n","  trg_img_path = img_path.replace(\"val_LR\", \"val_HR\")\n","  trg_file = tf.io.read_file(trg_img_path)\n","  trg_img = tf.image.decode_png(trg_file, channels=3)\n","  trg_img_npy = trg_img.numpy()\n","  trg_img = tf.expand_dims(trg_img, axis=0)\n","  trg_img = tf.cast(trg_img, tf.float32)\n","\n","\n","\n","  return lr_img[0], upsamp_img, sr_img[0] , trg_img[0]\n","\n","\n","def plot_edsr_results(orig, bicubic, super_res):\n","  fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n","  plt.subplot(221)\n","  plt.imshow(orig/255.)\n","  plt.title('Original Image')\n","  plt.axis(\"off\")\n","  plt.subplot(222)\n","  plt.axis(\"off\")\n","  plt.subplot(223)\n","  plt.imshow(bicubic)\n","  plt.title('Bicubic Upsampled Image')\n","  plt.axis(\"off\")\n","  plt.subplot(224)\n","  plt.imshow(super_res)\n","  plt.title('Super Resolution Image')\n","  plt.axis(\"off\")\n","  fig.tight_layout();"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lr_img_loc = 'sample image'\n","lr, bicubic, sr = run_sr_inference(lr_img_loc,\n","                                   edsr_model)\n","plot_edsr_results(lr, bicubic, sr)"],"metadata":{"id":"Nk8R8O0d42tA"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PU1CQgRHJ98H"},"source":["edsr_model.save_weights('/content/drive/MyDrive/edsr_16-res-block-x4.h5')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OoOkC5qCKdb_"},"source":["from tensorflow.keras.layers import BatchNormalization, \\\n","          Conv2D, Dense, Flatten, Input, LeakyReLU, Lambda\n","from tensorflow.keras.models import Model\n","\n","def minmax_normalize(x):\n","  \"\"\"Normalizes RGB images to [-1, 1].\"\"\"\n","  return x / 127.5 - 1\n","\n","\n","def srgan_discriminator_arch():\n","  hr_size=96\n","  inp = Input(shape=(hr_size, hr_size, 3))\n","  x = Lambda(minmax_normalize)(inp)\n","\n","  x = Conv2D(filters=64, kernel_size=3, \n","             strides=1, padding='same')(x)\n","  x = LeakyReLU(alpha=0.2)(x)\n","  x = Conv2D(filters=64, kernel_size=3, \n","             strides=2, padding='same')(x)\n","  x = BatchNormalization(momentum=0.8)(x)           \n","  x = LeakyReLU(alpha=0.2)(x)\n","\n","  x = Conv2D(filters=128, kernel_size=3, \n","             strides=1, padding='same')(x)\n","  x = BatchNormalization(momentum=0.8)(x)           \n","  x = LeakyReLU(alpha=0.2)(x)\n","  x = Conv2D(filters=128, kernel_size=3, \n","             strides=2, padding='same')(x)\n","  x = BatchNormalization(momentum=0.8)(x)           \n","  x = LeakyReLU(alpha=0.2)(x)\n","\n","  x = Conv2D(filters=256, kernel_size=3, \n","             strides=1, padding='same')(x)\n","  x = BatchNormalization(momentum=0.8)(x)           \n","  x = LeakyReLU(alpha=0.2)(x)\n","  x = Conv2D(filters=256, kernel_size=3, \n","             strides=2, padding='same')(x)\n","  x = BatchNormalization(momentum=0.8)(x)           \n","  x = LeakyReLU(alpha=0.2)(x)\n","\n","  x = Conv2D(filters=512, kernel_size=3, \n","             strides=1, padding='same')(x)\n","  x = BatchNormalization(momentum=0.8)(x)           \n","  x = LeakyReLU(alpha=0.2)(x)\n","  x = Conv2D(filters=512, kernel_size=3, \n","             strides=2, padding='same')(x)\n","  x = BatchNormalization(momentum=0.8)(x)           \n","  x = LeakyReLU(alpha=0.2)(x)\n","\n","  x = Flatten()(x)\n","  x = Dense(1024)(x)\n","  x = LeakyReLU(alpha=0.2)(x)\n","  out = Dense(1, activation='sigmoid')(x)\n","\n","  return Model(inp, out)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F_MNj_MKKX63"},"source":["generator = edsr_model_arch(num_residual_blocks=16)\n","generator.load_weights('/content/drive/MyDrive/edsr_16-res-block-x4.h5')\n","\n","discriminator = srgan_discriminator_arch()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZbPTKdbgGIYw"},"source":["generator.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"krnS1MobGL8D"},"source":["tf.keras.utils.plot_model(generator, show_shapes=True, \n","                          rankdir='TB')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XZ4OiwaBGqcP"},"source":["discriminator.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SfJ5nHBVG4XT"},"source":["tf.keras.utils.plot_model(discriminator, show_shapes=True, \n","                          rankdir='TB')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bJJRO0IIG-7S"},"source":["from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n","\n","lr_schedule = PiecewiseConstantDecay(boundaries=[100000, 200000], \n","                                     values=[1e-4, 1e-5, 5e-6])\n","generator_optim = Adam(learning_rate=lr_schedule)\n","discriminator_optim = Adam(learning_rate=lr_schedule)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ylu6yqRrT3zp"},"source":["from tensorflow.keras.applications import vgg19\n","\n","vgg = vgg19.VGG19(input_shape=(None, None, 3), \n","                  weights='imagenet',\n","                  include_top=False)\n","cutvgg_model = Model(vgg.input, vgg.layers[20].output)\n","\n","cutvgg_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jqb7-rtOH_My"},"source":["mse_loss = tf.keras.losses.MeanSquaredError()\n","bce_loss = tf.keras.losses.BinaryCrossentropy()\n","\n","def compute_generator_loss(sr_pred):\n","  return bce_loss(tf.ones_like(sr_pred), sr_pred)\n","\n","def compute_discriminator_loss(hr_pred, sr_pred):\n","  hr_loss = bce_loss(tf.ones_like(hr_pred), hr_pred)\n","  sr_loss = bce_loss(tf.zeros_like(sr_pred), sr_pred)\n","  return hr_loss + sr_loss\n","\n","@tf.function\n","def compute_content_loss(hr, sr):\n","  hr = vgg19.preprocess_input(hr)\n","  sr = vgg19.preprocess_input(sr)\n","  hr_deep_features = cutvgg_model(hr) / 12.75\n","  sr_deep_features = cutvgg_model(sr) / 12.75\n","  return mse_loss(hr_deep_features, sr_deep_features)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sUzMps63KxvI"},"source":["@tf.function\n","def train_step(lr_img_batch, hr_img_batch):\n","  \"\"\"SRGAN training step.\n","  \n","  Takes an LR and an HR image batch as input and returns\n","  the computed perceptual loss and discriminator loss.\n","  \"\"\"\n","  with tf.GradientTape() as gen_tape,\\\n","          tf.GradientTape() as disc_tape:\n","    lr_img_batch = tf.cast(lr_img_batch, tf.float32)\n","    hr_img_batch = tf.cast(hr_img_batch, tf.float32)\n","\n","    # Forward pass\n","    sr_gen_batch = generator(lr_img_batch, training=True)\n","    hr_pred = discriminator(hr_img_batch, training=True)\n","    sr_pred = discriminator(sr_gen_batch, training=True)\n","\n","    # Compute losses\n","    content_loss = compute_content_loss(hr_img_batch, \n","                                        sr_gen_batch)\n","    gen_loss = compute_generator_loss(sr_pred)\n","    perceptual_loss = content_loss + 1e-3 * gen_loss\n","    disc_loss = compute_discriminator_loss(hr_pred, sr_pred)\n","\n","  # Compute gradient of perceptual loss w.r.t. generator weights \n","  gen_grads = gen_tape.gradient(perceptual_loss, \n","                                generator.trainable_variables)\n","  # Compute gradient of discriminator loss w.r.t. discriminator weights \n","  disc_grads = disc_tape.gradient(disc_loss, \n","                                  discriminator.trainable_variables)\n","\n","  # Update weights of generator and discriminator\n","  generator_optim.apply_gradients(zip(gen_grads, \n","                                      generator.trainable_variables))\n","  discriminator_optim.apply_gradients(zip(disc_grads, \n","                                          discriminator.trainable_variables))\n","\n","  return perceptual_loss, disc_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jjYMf6StNazb"},"source":["total_steps = 300000\n","step = 0\n","pl_batch = []\n","dl_batch = []\n","for lr_batch, sr_batch in tqdm(train_ds.take(total_steps)):\n","  pl, dl = train_step(lr_batch, sr_batch)\n","  pl_batch.append(pl)\n","  dl_batch.append(dl)\n","  step += 1\n","\n","  if step % 1000 == 0:\n","    print('Step: {step}/{steps}: Perceptual Loss: {ploss:.5f}, Discriminator Loss: {dloss:.5f}'.format(\n","        step=step, steps=total_steps,\n","        ploss=np.mean(pl_batch),\n","        dloss=np.mean(dl_batch)\n","    ))\n","    pl_batch = []\n","    dl_batch = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XzVh1_83SUyW"},"source":["generator.save_weights('/content/drive/MyDrive/srgan_finetuned_edsr_16-res-block-x4.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ky-xe5Mborq"},"source":["#LOAD MODEL AND WEIGHTS\n","weight_edsr = f\"/content/drive/MyDrive/South Pole/training_weights_logs/weights/second_module/l8_s2_training/edsr_16-res-block-x4.h5\"\n","weight_srgan = f\"/content/drive/MyDrive/South Pole/training_weights_logs/weights/second_module/l8_s2_training/srgan_finetuned_edsr_16-res-block-x4.h5\"\n","\n","\n","edsr_orig_model = edsr_model_arch(num_residual_blocks=16)\n","edsr_orig_model.load_weights(weight_edsr)\n","\n","edsr_finetuned_model = edsr_model_arch(num_residual_blocks=16)\n","edsr_finetuned_model.load_weights(weight_srgan)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CREATE THE PREDICTION FILE FOR EACH IMAGE IN VALIDATION SET\n","\n","model = edsr_finetuned_model\n","model_name = \"M2_SRGAN_l8_s2\"\n","output_directory = \"PREDICTIONS DIRECTORY\"\n","input_directory = \"LR IMAGES DIRECTORY\"\n","\n","filenames = list()\n","output_directory = output_directory + \"/\" + model_name\n","os.makedirs(output_directory)\n","\n","for filename in os.listdir(input_directory):\n","      f = os.path.join(input_directory, filename)\n","      # checking if it is a file\n","      if os.path.isfile(f) and filename.split(\".\")[-1] == \"png\":\n","        filenames.append(f)\n","      \n","for input_path in filenames:\n","  \n","  output_file = input_path.split(\"/\")[-1]\n","  output_path = os.path.join(output_directory,output_file)\n","\n","  lr_file = tf.io.read_file(input_path)\n","  lr_img = tf.image.decode_png(lr_file, channels=3)\n","  lr_img_npy = lr_img.numpy()\n","\n","  lr_img = tf.expand_dims(lr_img, axis=0)\n","  lr_img = tf.cast(lr_img, tf.float32)\n","\n","  sr_img = model(lr_img)\n","  sr_img = tf.clip_by_value(sr_img, 0, 255)\n","  sr_img = tf.cast(sr_img, tf.uint8)\n","  tf.keras.preprocessing.image.save_img(output_path,sr_img[0])  \n","\n","\n","\n"],"metadata":{"id":"aGA7J59lVb-7"},"execution_count":null,"outputs":[]}]}