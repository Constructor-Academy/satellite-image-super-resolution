{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ISR_training_RDN_x3_PSNR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install ISR"
      ],
      "metadata": {
        "id": "NANJnBwd6RNX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapted by Ozgun Haznedaar from ISR_Training_Tutorial.ipynb: https://github.com/\n",
        "idealo/image-super-resolution/tree/master/notebooks\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cb8nbPUMsLa_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this notebook is to set up a model from the ISR repo and train it."
      ],
      "metadata": {
        "id": "ERsguvN-sU12"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEFfJc3S2Hqf",
        "outputId": "4fc925ce-d08d-4189-e5d2-6a72511b8484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%cd /content/drive/MyDrive/image-super-resolution\n",
        "!python setup.py install\n",
        "!pip install 'h5py==2.10.0' --force-reinstall\n",
        "!pip install -U PyYAML\n",
        "!pip install imagecodecs\n",
        "\n",
        "\n",
        "# if using local repo of ISR\n",
        "# else use !pip install ISR and see ISR_module_adjustments notebook for changes\n",
        "# to run locally\n",
        "#!pip install gast>=0.3.2\n",
        "#!pip install ISR"
      ],
      "metadata": {
        "id": "kdkgGVUCJpVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "Ix-SoK9O6XlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ISR.models import RDN\n",
        "from ISR.models import Discriminator\n",
        "from ISR.models import Cut_VGG19"
      ],
      "metadata": {
        "id": "HKR5vgcO4wKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_train_patch_size = 60\n",
        "layers_to_extract = [5, 9]\n",
        "scale = 3\n",
        "hr_train_patch_size = lr_train_patch_size * scale\n",
        "\n",
        "rdn  = RDN(arch_params={'C':3, 'D':10, 'G':64, 'G0':64, 'x': scale }, patch_size=lr_train_patch_size)\n",
        "\n",
        "#rdn  = RDN(arch_params={'C':6, 'D':20, 'G':64, 'G0':64, 'x': scale }, patch_size=lr_train_patch_size) # for large RDN\n",
        "\n",
        "f_ext = Cut_VGG19(patch_size=hr_train_patch_size, layers_to_extract=layers_to_extract)\n",
        "discr = Discriminator(patch_size=hr_train_patch_size, kernel_size=3)"
      ],
      "metadata": {
        "id": "GtiwUQNM6yEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Give the models to the Trainer\n",
        "The Trainer object will combine the networks, manage your training data and keep you up-to-date with the training progress through Tensorboard and the command line.\n",
        "\n",
        "Here we do not use  the pixel-wise MSE but only the perceptual loss by specifying the respective weights in `loss_weights`"
      ],
      "metadata": {
        "id": "TNEGk75K7jmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ISR.train import Trainer\n",
        "loss_weights = {\n",
        "  'generator': 1.0, #0.0\n",
        "  'feature_extractor': 0.0, #0.0833\n",
        "  'discriminator': 0.00 #0.01\n",
        "}\n",
        "losses = {\n",
        "  'generator': 'mae',\n",
        "  'feature_extractor': 'mse',\n",
        "  'discriminator': 'binary_crossentropy'\n",
        "} \n",
        "\n",
        "log_dirs = {'logs': '/content/drive/MyDrive/logs', 'weights': '/content/drive/MyDrive/weights'}\n",
        "\n",
        "learning_rate = {'initial_value': 0.0004, 'decay_factor': 0.5, 'decay_frequency': 30}\n",
        "\n",
        "flatness = {'min': 0.0, 'max': 0.15, 'increase': 0.01, 'increase_frequency': 5}\n",
        "\n",
        "trainer = Trainer(\n",
        "    generator=rdn,\n",
        "    discriminator=discr,\n",
        "    feature_extractor=f_ext,\n",
        "    lr_train_dir='PATH TO LR TRAINING DATA',\n",
        "    hr_train_dir='PATH TO HR TRAINING DATA',\n",
        "    lr_valid_dir='PATH TO LR VALIDATION DATA',\n",
        "    hr_valid_dir='PATH TO HR VALIDATION DATA',\n",
        "    loss_weights=loss_weights,\n",
        "    learning_rate=learning_rate,\n",
        "    flatness=flatness,\n",
        "    dataname='div2kx3_rdn_small',\n",
        "    log_dirs=log_dirs,\n",
        "    weights_generator=None,\n",
        "    weights_discriminator=None,\n",
        "    n_validation=60,\n",
        ")\n"
      ],
      "metadata": {
        "id": "uo8pyvoh7Y8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose epoch number, steps and batch size and start training"
      ],
      "metadata": {
        "id": "xXOlkYCM8K7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train(\n",
        "    epochs=150,\n",
        "    steps_per_epoch=20,\n",
        "    batch_size=4,\n",
        "    monitored_metrics={'val_generator_PSNR_Y':'max','val_discriminator_loss':'min', 'val_feature_extractor_loss':'min'}\n",
        ")"
      ],
      "metadata": {
        "id": "82f2whBc8Mux"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}